{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIML Predictions\n",
    "\n",
    "In this notebook we train and evaluate CIML experiments using the functions `gather_results` and `tf_trainer functions` of the [ciml project](https://github.com/mtreinish/ciml). \n",
    "<br>Then we save the predictions of the experiments for a deeper analysis of the metrics of the trained models (see [CIML Metric Report](https://nbviewer.jupyter.org/github/kwulffert/ciml_experiments/blob/master/Metrics%20report.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ciml import gather_results\n",
    "from ciml import tf_trainer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.training import adagrad\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the data path, dataset and experiment to gather the right input dataset and the configuration for the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/kw/ciml_data/cimlodsceu2019seed'\n",
    "\n",
    "#Dataset and experiment combination for multiple classification\n",
    "#dataset = 'usr_1m-1min-node_provider'\n",
    "#experiment = 'dnn-3x100-500epochs-bs128'\n",
    "\n",
    "#Dataset and experiment combination for binary classification\n",
    "dataset = 'usr_1m-1min-status'\n",
    "experiment = 'dnn-5x100-500epochs-bs128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data = gather_results.load_experiment(\n",
    "        experiment, data_path=data_path)\n",
    "dataset_data = gather_results.load_model_config(\n",
    "        dataset, data_path=data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "The dataset and experiment_data are dictionaries with the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['build_name', 'sample_interval', 'features_regex', 'class_label', 'aggregation_functions', 'training_set', 'dev_set', 'test_set', 'normalized_length', 'labels', 'num_columns', 'num_features', 'normalization_params'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator': 'tf.estimator.DNNClassifier',\n",
       " 'params': {},\n",
       " 'hyper_params': {'steps': 9500,\n",
       "  'batch_size': '128',\n",
       "  'epochs': '500',\n",
       "  'hidden_units': [100, 100, 100, 100, 100],\n",
       "  'optimizer': 'Adagrad',\n",
       "  'learning_rate': 0.05}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set up the experiment and configure the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = experiment_data['estimator']\n",
    "hyper_params = experiment_data['hyper_params']\n",
    "params = experiment_data['params']\n",
    "steps = int(hyper_params['steps'])\n",
    "num_epochs = int(hyper_params['epochs'])\n",
    "batch_size = int(hyper_params['batch_size'])\n",
    "optimizer = hyper_params['optimizer']\n",
    "learning_rate = float(hyper_params['learning_rate'])\n",
    "class_label = dataset_data['class_label']\n",
    "labels = gather_results.load_dataset(dataset, 'labels', data_path=data_path)['labels']\n",
    "training_data = gather_results.load_dataset(dataset, 'training', data_path=data_path)\n",
    "test_data = gather_results.load_dataset(dataset, 'test', data_path=data_path)\n",
    "\n",
    "#label_vocabulary = None\n",
    "if class_label == 'node_provider':\n",
    "    label_vocabulary = set(['rax', 'ovh', 'packethost-us-west-1',\n",
    "                            'vexxhost', 'limestone-regionone',\n",
    "                            'inap-mtl01', 'fortnebula-regionone'])\n",
    "elif class_label == 'node_provider_all':\n",
    "    label_vocabulary = set(['rax-iad', 'ovh-bhs1', 'packethost-us-west-1',\n",
    "                            'rax-dfw', 'vexxhost-ca-ymq-1', 'ovh-gra1',\n",
    "                            'limestone-regionone', 'inap-mtl01', 'rax-ord',\n",
    "                            'vexxhost-sjc1', 'fortnebula-regionone'])\n",
    "else:\n",
    "    label_vocabulary = None\n",
    "\n",
    "model_dir = gather_results.get_model_folder(dataset, experiment, data_path=data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/Users/kw/ciml_data/cimlodsceu2019seed/usr_1m-1min-status/dnn-5x100-500epochs-bs128', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 300, '_session_config': allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf_trainer.get_estimator(\n",
    "        estimator, hyper_params, params, labels, model_dir,\n",
    "        optimizer=adagrad.AdagradOptimizer(learning_rate=0.05),\n",
    "        label_vocabulary=label_vocabulary, gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /git/github.com/mtreinish/ciml/ciml/tf_trainer.py:35: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From /git/github.com/mtreinish/ciml/ciml/tf_trainer.py:35: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_fn=tf_trainer.get_input_fn(shuffle=True,\n",
    "                    batch_size=batch_size, num_epochs=num_epochs,\n",
    "                    labels=labels, **training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /Users/kw/ciml_data/cimlodsceu2019seed/usr_1m-1min-status/dnn-5x100-500epochs-bs128/model.ckpt-37144\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 37144...\n",
      "INFO:tensorflow:Saving checkpoints for 37144 into /Users/kw/ciml_data/cimlodsceu2019seed/usr_1m-1min-status/dnn-5x100-500epochs-bs128/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 37144...\n",
      "INFO:tensorflow:loss = 1.3504366e-06, step = 37144\n",
      "INFO:tensorflow:global_step/sec: 21.8992\n",
      "INFO:tensorflow:loss = 1.2049506e-06, step = 37244 (4.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7054\n",
      "INFO:tensorflow:loss = 2.0004976e-05, step = 37344 (4.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0073\n",
      "INFO:tensorflow:loss = 1.3013656e-05, step = 37444 (4.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1111\n",
      "INFO:tensorflow:loss = 1.563422e-05, step = 37544 (3.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4861\n",
      "INFO:tensorflow:loss = 4.0391706e-06, step = 37644 (4.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0983\n",
      "INFO:tensorflow:loss = 8.275286e-06, step = 37744 (3.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1329\n",
      "INFO:tensorflow:loss = 2.8324019e-05, step = 37844 (3.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1429\n",
      "INFO:tensorflow:loss = 4.532768e-06, step = 37944 (3.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6846\n",
      "INFO:tensorflow:loss = 7.873686e-06, step = 38044 (3.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8279\n",
      "INFO:tensorflow:loss = 5.083274e-06, step = 38144 (3.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4071\n",
      "INFO:tensorflow:loss = 2.0270869e-05, step = 38244 (3.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.087\n",
      "INFO:tensorflow:loss = 1.9464169e-05, step = 38344 (3.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0366\n",
      "INFO:tensorflow:loss = 1.453042e-05, step = 38444 (3.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.2827\n",
      "INFO:tensorflow:loss = 6.481775e-06, step = 38544 (3.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5632\n",
      "INFO:tensorflow:loss = 2.6403626e-05, step = 38644 (3.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3387\n",
      "INFO:tensorflow:loss = 1.6002063e-05, step = 38744 (3.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.4718\n",
      "INFO:tensorflow:loss = 1.2280428e-05, step = 38844 (3.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.4952\n",
      "INFO:tensorflow:loss = 6.334826e-06, step = 38944 (3.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0227\n",
      "INFO:tensorflow:loss = 4.653243e-06, step = 39044 (3.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1614\n",
      "INFO:tensorflow:loss = 5.00558e-06, step = 39144 (3.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.458\n",
      "INFO:tensorflow:loss = 3.0714896e-06, step = 39244 (3.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.3787\n",
      "INFO:tensorflow:loss = 9.098583e-06, step = 39344 (3.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.3739\n",
      "INFO:tensorflow:loss = 1.7420327e-05, step = 39444 (3.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.78\n",
      "INFO:tensorflow:loss = 6.040292e-06, step = 39544 (3.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1413\n",
      "INFO:tensorflow:loss = 6.987998e-06, step = 39644 (3.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.6999\n",
      "INFO:tensorflow:loss = 6.853454e-07, step = 39744 (3.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.2604\n",
      "INFO:tensorflow:loss = 1.145404e-05, step = 39844 (3.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2546\n",
      "INFO:tensorflow:loss = 1.4939065e-05, step = 39944 (3.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.4936\n",
      "INFO:tensorflow:loss = 7.820557e-06, step = 40044 (3.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8892\n",
      "INFO:tensorflow:loss = 2.2555505e-06, step = 40144 (3.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3316\n",
      "INFO:tensorflow:loss = 3.1253608e-06, step = 40244 (3.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.0579\n",
      "INFO:tensorflow:loss = 9.1523125e-06, step = 40344 (3.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6511\n",
      "INFO:tensorflow:loss = 1.9122246e-05, step = 40444 (3.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.8338\n",
      "INFO:tensorflow:loss = 7.649923e-06, step = 40544 (3.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3312\n",
      "INFO:tensorflow:loss = 1.3856525e-05, step = 40644 (3.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0553\n",
      "INFO:tensorflow:loss = 1.5189317e-05, step = 40744 (3.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.2692\n",
      "INFO:tensorflow:loss = 7.875381e-06, step = 40844 (3.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5945\n",
      "INFO:tensorflow:loss = 1.4867585e-05, step = 40944 (6.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1818\n",
      "INFO:tensorflow:loss = 6.7179567e-06, step = 41044 (3.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7371\n",
      "INFO:tensorflow:loss = 5.1487987e-06, step = 41144 (3.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8909\n",
      "INFO:tensorflow:loss = 1.3124938e-05, step = 41244 (5.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5276\n",
      "INFO:tensorflow:loss = 1.8993039e-06, step = 41344 (8.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4984\n",
      "INFO:tensorflow:loss = 1.5874844e-05, step = 41444 (5.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.7561\n",
      "INFO:tensorflow:loss = 6.5827685e-06, step = 41544 (4.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7979\n",
      "INFO:tensorflow:loss = 3.8148396e-06, step = 41644 (4.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4257\n",
      "INFO:tensorflow:loss = 3.862424e-05, step = 41744 (4.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.8045\n",
      "INFO:tensorflow:loss = 2.3463185e-06, step = 41844 (5.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1974\n",
      "INFO:tensorflow:loss = 6.391e-06, step = 41944 (4.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8786\n",
      "INFO:tensorflow:loss = 7.811261e-06, step = 42044 (4.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8348\n",
      "INFO:tensorflow:loss = 1.0984784e-05, step = 42144 (6.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16771\n",
      "INFO:tensorflow:loss = 5.1152156e-06, step = 42244 (16.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.81454\n",
      "INFO:tensorflow:loss = 5.8964383e-06, step = 42344 (14.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3383\n",
      "INFO:tensorflow:loss = 1.2148777e-05, step = 42444 (5.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9245\n",
      "INFO:tensorflow:loss = 1.2135953e-05, step = 42544 (3.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6181\n",
      "INFO:tensorflow:loss = 1.6403994e-05, step = 42644 (3.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7641\n",
      "INFO:tensorflow:loss = 3.4684113e-06, step = 42744 (3.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1757\n",
      "INFO:tensorflow:loss = 1.7617731e-05, step = 42844 (3.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3524\n",
      "INFO:tensorflow:loss = 1.1223226e-05, step = 42944 (3.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2847\n",
      "INFO:tensorflow:loss = 5.080265e-06, step = 43044 (4.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9142\n",
      "INFO:tensorflow:loss = 5.9241092e-06, step = 43144 (4.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6224\n",
      "INFO:tensorflow:loss = 1.3638857e-05, step = 43244 (4.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.176\n",
      "INFO:tensorflow:loss = 3.4641475e-06, step = 43344 (3.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.677\n",
      "INFO:tensorflow:loss = 9.996355e-06, step = 43444 (4.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8766\n",
      "INFO:tensorflow:loss = 3.918278e-06, step = 43544 (4.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3648\n",
      "INFO:tensorflow:loss = 3.2331534e-06, step = 43644 (3.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.9303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.7563398e-06, step = 43744 (3.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2461\n",
      "INFO:tensorflow:loss = 1.5482317e-05, step = 43844 (3.673 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 43929...\n",
      "INFO:tensorflow:Saving checkpoints for 43929 into /Users/kw/ciml_data/cimlodsceu2019seed/usr_1m-1min-status/dnn-5x100-500epochs-bs128/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 43929...\n",
      "INFO:tensorflow:global_step/sec: 24.8964\n",
      "INFO:tensorflow:loss = 1.274326e-05, step = 43944 (4.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3871\n",
      "INFO:tensorflow:loss = 3.14791e-06, step = 44044 (3.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.4954\n",
      "INFO:tensorflow:loss = 1.28753745e-05, step = 44144 (4.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8688\n",
      "INFO:tensorflow:loss = 1.4783594e-05, step = 44244 (3.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0669\n",
      "INFO:tensorflow:loss = 2.0092357e-05, step = 44344 (4.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.9826\n",
      "INFO:tensorflow:loss = 5.5030687e-06, step = 44444 (3.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9483\n",
      "INFO:tensorflow:loss = 2.9894827e-06, step = 44544 (3.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1667\n",
      "INFO:tensorflow:loss = 8.239074e-06, step = 44644 (3.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9226\n",
      "INFO:tensorflow:loss = 9.301704e-06, step = 44744 (3.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5138\n",
      "INFO:tensorflow:loss = 2.8172853e-06, step = 44844 (3.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1337\n",
      "INFO:tensorflow:loss = 1.0511039e-06, step = 44944 (3.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.2729\n",
      "INFO:tensorflow:loss = 3.2223008e-06, step = 45044 (3.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5587\n",
      "INFO:tensorflow:loss = 5.8454057e-06, step = 45144 (3.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.3464\n",
      "INFO:tensorflow:loss = 3.6826686e-06, step = 45244 (3.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4876\n",
      "INFO:tensorflow:loss = 1.2164576e-06, step = 45344 (3.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4815\n",
      "INFO:tensorflow:loss = 1.4062962e-05, step = 45444 (3.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.4953\n",
      "INFO:tensorflow:loss = 9.608109e-06, step = 45544 (3.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5243\n",
      "INFO:tensorflow:loss = 1.8879822e-06, step = 45644 (3.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2383\n",
      "INFO:tensorflow:loss = 1.12892885e-05, step = 45744 (3.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.529\n",
      "INFO:tensorflow:loss = 2.3893422e-06, step = 45844 (4.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9303\n",
      "INFO:tensorflow:loss = 1.4651994e-05, step = 45944 (5.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8395\n",
      "INFO:tensorflow:loss = 2.2380555e-06, step = 46044 (6.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.5461\n",
      "INFO:tensorflow:loss = 2.3839177e-06, step = 46144 (4.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2999\n",
      "INFO:tensorflow:loss = 5.45018e-06, step = 46244 (3.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.8046\n",
      "INFO:tensorflow:loss = 1.9873112e-05, step = 46344 (3.732 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 46430...\n",
      "INFO:tensorflow:Saving checkpoints for 46430 into /Users/kw/ciml_data/cimlodsceu2019seed/usr_1m-1min-status/dnn-5x100-500epochs-bs128/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 46430...\n",
      "INFO:tensorflow:Loss for final step: 4.2617327e-07.\n"
     ]
    }
   ],
   "source": [
    "training_result = tf_trainer.get_training_method(estimator)(\n",
    "                    input_fn=tf_trainer.get_input_fn(shuffle=True,\n",
    "                    batch_size=batch_size, num_epochs=num_epochs,\n",
    "                    labels=labels, **training_data), steps=steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the trained model with the testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = gather_results.load_dataset(dataset, 'test', data_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['examples', 'example_ids', 'classes'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_size = len(eval_data['example_ids'])\n",
    "eval_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We analyse the predictions of our trained model.\n",
    "<br>Info logging is enabled to monitor the status of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = estimator.predict(input_fn=tf_trainer.get_input_fn(\n",
    "                                batch_size=eval_size, num_epochs=1,\n",
    "                                labels=labels, **eval_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /Users/kw/ciml_data/cimlodsceu2019seed/usr_1m-1min-status/dnn-5x100-500epochs-bs128/model.ckpt-46430\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = [x for x in prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[744, 37, 7, 6]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_classes = [x[\"class_ids\"][0] for x in predictions]\n",
    "actual_classes = eval_data[\"classes\"]\n",
    "classes = zip(p_classes, actual_classes)\n",
    "counter = collections.Counter(classes)\n",
    "sorted(counter.values(), reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(0, 0): 744, (1, 1): 37, (0, 1): 7, (1, 0): 6})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the predictions of the trained model in a zipped json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializable_pred = []\n",
    "for pred in predictions:\n",
    "    _classes = pred['classes']\n",
    "    _all_classes = pred['all_classes']\n",
    "    pred['classes'] = [x.decode(\"utf-8\") for x in _classes]\n",
    "    pred['all_classes'] = [x.decode(\"utf-8\") for x in _all_classes]\n",
    "    serializable_pred.append(pred)\n",
    "\n",
    "prediction_name = \"prediction_\" + dataset\n",
    "pred_data = zip(eval_data['example_ids'], serializable_pred,\n",
    "                eval_data['classes'])\n",
    "gather_results.save_data_json(\n",
    "    dataset, [x for x in pred_data],\n",
    "    prediction_name, sub_folder=experiment, data_path=data_path)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": ".venv-mpl",
   "language": "python",
   "name": ".venv-mpl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
